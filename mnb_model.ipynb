{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code for the Multinomial Naive Bayes classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding mapping:\n",
      "{'negative': 0, 'positive': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"IMDB Dataset Processed Lemma test.csv\")\n",
    "\n",
    "###Representing the textual data in a suitable model (i.e. Bag of Words, TF-IDF Vectors)\n",
    "\n",
    "#Represent the text data using Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(df['cleaned_review'])\n",
    "\n",
    "#Alternatively, represent the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_review'])\n",
    "\n",
    "\n",
    "###Splitting the data into the training and test sets. Ensure that the train and test datasets are balanced by using stratify on the sentiments data\n",
    "\n",
    "#Labels (i.e. Sentiment)\n",
    "y = df['sentiment']\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "#Get the mapping of the numeric labels to the original labels\n",
    "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "print(\"Label encoding mapping:\")\n",
    "print(label_mapping)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_encoded, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the Multinomial Naive Bayes model here. We start off by conducting hyperparameter optimization using gridsearch to find the ideal hyperparameter. The ideal hyperparameter is one that allows the model to have the highest f1 score.\n",
    "Once we have found the ideal hyperparameter, we train the model using that specific hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 2.0\n",
      "Best F1 score: 0.8656498172192109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, make_scorer, f1_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the parameter grid for alpha\n",
    "param_grid = {'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]} # Smoothing parameter\n",
    "\n",
    "# Initialize the MultinomialNB classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Define the scoring metric with macro F1 score\n",
    "scoring = make_scorer(f1_score, average='micro')\n",
    "grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, scoring=scoring, cv=5) # Cross validation with 5 folds\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best F1 score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix is:\n",
      "[[17690  2068]\n",
      " [ 1996 17911]]\n",
      "Test confusion matrix is:\n",
      "[[4256  684]\n",
      " [ 661 4316]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      4940\n",
      "           1       0.86      0.87      0.87      4977\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n",
      "Train accuracy score:  0.8975419135257784\n",
      "Test accuracy score:  0.8643743067459917\n",
      "Train ROC-AUC score: 0.9616374100901312\n",
      "Test ROC-AUC score: 0.9390849730623215\n"
     ]
    }
   ],
   "source": [
    "# Train the MultinomialNB classifier with the best alpha (Lidstone Smoothing)\n",
    "mnb_classifier = MultinomialNB(alpha=best_alpha)\n",
    "mnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes and the probabilities using the best model\n",
    "predicted_class = mnb_classifier.predict(X_test)\n",
    "predicted_class_train = mnb_classifier.predict(X_train)\n",
    "test_probs = mnb_classifier.predict_proba(X_test)\n",
    "train_probs = mnb_classifier.predict_proba(X_train)\n",
    "\n",
    "# Calculate and print the performance metrics\n",
    "print('Train confusion matrix is:')\n",
    "print(confusion_matrix(y_train, predicted_class_train))\n",
    "print('Test confusion matrix is:')\n",
    "print(confusion_matrix(y_test, predicted_class))\n",
    "print(classification_report(y_test, predicted_class))\n",
    "\n",
    "# Calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, predicted_class_train)\n",
    "test_accuracy = accuracy_score(y_test, predicted_class)\n",
    "print(\"Train accuracy score: \", train_accuracy)\n",
    "print(\"Test accuracy score: \", test_accuracy)\n",
    "\n",
    "# Calculate and print the AUC-ROC score\n",
    "train_auc = roc_auc_score(y_train, train_probs[:, 1], multi_class = 'ovr')\n",
    "test_auc = roc_auc_score(y_test, test_probs[:, 1], multi_class='ovr')\n",
    "print(\"Train ROC-AUC score:\", train_auc)\n",
    "print(\"Test ROC-AUC score:\", test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
